# üèÅ Aula 10: Revis√£o Geral e Integra√ß√£o em Contextos Avan√ßados

**Data:** 11/11/2025  
**Institui√ß√£o:** ISEC - Instituto Superior de Engenharia de Coimbra  
**Curso:** CTeSP em Tecnologias e Programa√ß√£o de Sistemas de Informa√ß√£o  
**Professor:** Jo√£o Leal  

---

## üìù Sum√°rio da Aula

Nesta √∫ltima aula de conte√∫dos curriculares, realiz√°mos uma revis√£o transversal dos conceitos abordados ao longo da Unidade Curricular, consolidando os fundamentos de ETL. A sess√£o avan√ßou para t√≥picos de **Integra√ß√£o em Contextos Avan√ßados**, focando-se nos desafios do Big Data, tempo real e qualidade de dados.

A aula culminou com a resolu√ß√£o da **Tarefa #07**, onde aplic√°mos processos de extra√ß√£o de dados via **REST APIs** e lan√ß√°mos o Trabalho Final da disciplina.

* **Revis√£o de Fundamentos:** O ciclo de vida ETL e a heterogeneidade das fontes de dados.
* **Integra√ß√£o em Tempo Real:**
    * Diferen√ßa entre processamento *Batch* (Lotes) vs. *Real-Time* (Streaming).
    * T√©cnicas de **CDC** (Change Data Capture) para sincroniza√ß√£o imediata.
    * Uso de *Message Queues* (ex: Apache Kafka, RabbitMQ).
* **Big Data e Arquiteturas Modernas:**
    * Os 3 Vs do Big Data: Volume, Velocidade e Variedade.
    * Evolu√ß√£o do armazenamento: *Data Warehouse* vs. *Data Lake* vs. *Lakehouse*.
* **Governan√ßa e Qualidade:**
    * **Data Profiling:** An√°lise estat√≠stica para entender a estrutura dos dados.
    * **Data Cleansing:** Processos de limpeza e normaliza√ß√£o.
    * **MDM (Master Data Management):** Cria√ß√£o de uma "fonte de verdade √∫nica" para entidades cr√≠ticas (Clientes, Produtos).

---

## üõ†Ô∏è Cen√°rios Pr√°ticos: Consumo de APIs

A vertente pr√°tica focou-se na integra√ß√£o de sistemas distribu√≠dos, abandonando os ficheiros locais em favor de dados din√¢micos obtidos via Web Services.

### Desafios da Tarefa #07
1.  **Consumo de APIs REST:** Utiliza√ß√£o da biblioteca `requests` para m√©todos GET.
2.  **JSON Parsing:** Tratamento de dados semi-estruturados e convers√£o para tabelas (DataFrames).
3.  **Visualiza√ß√£o:** Gera√ß√£o de gr√°ficos a partir de dados da NASA.
4.  **Carga em Base de Dados:** Persist√™ncia dos dados transformados em SQLite.

---

## üíª Exemplo de Implementa√ß√£o (ETL com API e SQLite)

Abaixo apresento a resolu√ß√£o do **Exerc√≠cio 4**, que ilustra um pipeline completo: extrair produtos de uma API fict√≠cia, aplicar regras de neg√≥cio (c√°lculo de IVA e filtragem) e carregar para uma base de dados relacional.

```python
import pandas as pd
import requests
import sqlite3

# --- 1. EXTRA√á√ÉO (Extract) ---
# Obter dados de produtos de uma API p√∫blica
url = "[https://fakestoreapi.com/products](https://fakestoreapi.com/products)"
response = requests.get(url)

if response.status_code == 200:
    data = response.json()
    df_produtos = pd.DataFrame(data)
    
    # --- 2. TRANSFORMA√á√ÉO (Transform) ---
    
    # A. Sele√ß√£o de colunas relevantes
    cols = ['id', 'title', 'price', 'category']
    df_produtos = df_produtos[cols]
    
    # B. Limpeza: Remover produtos com pre√ßo 0 ou negativo
    df_produtos = df_produtos[df_produtos['price'] > 0]
    
    # C. Enriquecimento: Calcular pre√ßo com IVA (23%)
    # Regra: Novo Pre√ßo = Pre√ßo * 1.23
    df_produtos['preco_com_iva'] = df_produtos['price'] * 1.23
    df_produtos['preco_com_iva'] = df_produtos['preco_com_iva'].round(2)
    
    print(f"Dados transformados: {len(df_produtos)} registos.")
    
    # --- 3. CARGA (Load) ---
    
    # Conectar a uma base de dados SQLite local
    conn = sqlite3.connect('loja_integracao.db')
    
    # Escrever o DataFrame na tabela 'produtos'
    # if_exists='replace' recria a tabela a cada execu√ß√£o
    df_produtos.to_sql('produtos', conn, if_exists='replace', index=False)
    
    conn.close()
    print("Sucesso: Dados carregados na base de dados SQLite.")

else:
    print(f"Erro ao aceder √† API: {response.status_code}")


